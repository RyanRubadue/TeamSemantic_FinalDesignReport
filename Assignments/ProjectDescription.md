
This project aimed to develop a natural language processing (NLP) algorithm using Python that could process large documents and create word clouds and cluster maps by embedding and clustering sentences. The algorithm uses various filtering parameters to remove irrelevant information, and the number of clusters is optimized for each parameter change. The effectiveness of different filtering parameters is then compared to select the most suitable approach. Overall, this project provides a powerful tool for text analysis and visualization, which could have applications in various domains.
